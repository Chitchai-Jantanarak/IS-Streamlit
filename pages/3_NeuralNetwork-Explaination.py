import streamlit as st

def preparation() -> None :
    st.markdown("<a id='dataset-preparation'></a>", unsafe_allow_html=True)
    st.markdown("""
    ## Dataset Preparation

    ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏¥‡∏ö‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å   "[kaggle](https://www.kaggle.com/)" <br />
    [<span style="color:blue">‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û X-ray (Chest X-ray Images diagnose PNEUMONIA)</span>](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
    """, unsafe_allow_html=1)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏ó‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏†‡∏≤‡∏û X-ray ‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å :
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏∂‡∏ö‡πÅ‡∏™‡∏á, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ü‡∏∏‡πâ‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏™‡∏á
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤‡πÅ‡∏ô‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠
    - ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ç‡∏≠‡∏á‡∏õ‡∏≠‡∏î ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏ß‡∏°
    - ‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏≠‡∏°‡∏•‡∏°
    """)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Images ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡πÑ‡∏ü‡∏•‡πå 
    ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πâ‡∏á 3 ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö "‡∏õ‡∏Å‡∏ï‡∏¥-‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö(‡πÑ‡∏°‡πà‡πÅ‡∏¢‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡∏≠‡∏á‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö)" ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß

        - test
            test/NORMAL
            test/PNEUMONIA
        - train 
            train/NORMAL
            train/PNEUMONIA
        - val
            val/NORMAL
            val/PNEUMONIA
    """)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.image('public/neural_network/dataprep_images.jpg')

    st.markdown("""
    ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏¢‡∏Å‡∏ä‡∏ô‡∏¥‡∏î‡πÉ‡∏´‡πâ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ 
    ‡∏à‡∏∂‡∏á‡∏ô‡∏≥‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏µ‡πà‡πÉ‡∏ô directory ‡∏°‡∏≤ random ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏µ‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô samples ‡πÄ‡∏Å‡πà‡∏≤‡πÜ ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

    ```python
    # EXAMPLE !
    # ‡∏ô‡∏≥‡∏ä‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏ß‡πâ e.g. ‚àÄ(train) + 0.05(test)
    # remark: ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ testing ‡πÅ‡∏ï‡πà‡∏ó‡∏≥‡πÑ‡∏ß‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ :)          

    train_x = tf.keras.utils.image_dataset_from_directory(
        str(data_dir),
        color_mode='rgb',
        seed=123,
        image_size=(224, 224),
        batch_size=32,
    )

    # 0.05 of test
    test_x_sample = tf.keras.utils.image_dataset_from_directory(
        str(data_dir),
        color_mode='rgb',
        seed=123,
        image_size=(224, 224),
        batch_size=32,
        validation_split=0.05, 
        subset='validation', 
    )
                
    for image, label in test_x_sample:
        train_x = train_x.concatenate(
            tf.data.Dataset.from_tensor_slices((image, label))
        )
                
    # dataset = [[image, label], [...], ...]
    ```
    """)

    st.markdown("---")

def workflow() -> None :
    st.markdown("<a id='workflow'></a>", unsafe_allow_html=True)
    st.markdown("""
    ## WORKFLOW
                
    ##### Model ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ : [Convolutional neural network (CNN)](https://www.tensorflow.org/tutorials/images/cnn?hl=en)
    
    ###### ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ CNN model
                
    Convolutional Neural Network (CNN) ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Learning 
    ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏î‡∏à‡∏≥‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏•‡∏∞
    ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏∂‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡πç‡∏ç‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÑ‡∏î‡πâ ‡∏ú‡πà‡∏≤‡∏ô Activation Function ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ layer
    """,)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£ training ‡πÉ‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô CNN + [VGG16 model](https://keras.io/api/applications/vgg/) (CNN classify images)
    ##### Activation Function
    - (ReLU : Convolutional)
    - (Sigmoid : Fully connected)
    """)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### 1. ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô, ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ samples
                
    ```python
    # __builder_model.py

    base_path = '.....' # Data PATH   
                
    def load_image(base_path) -> tuple:
          
        # Load images from the specified directory
        #
        # Args:
        #     base_path (str): Base path to the image directory 
        #     [INNER : {PreData : test, train, val}]
        #
        # Returns:
        #     Tuple of (train_dataset, validation_dataset)
          
        
        data_dir = pathlib.Path(base_path)

        if not data_dir.exists():
            raise ValueError(f"Director does not exist: {data_dir}")
        
        train_x = tf.keras.utils.image_dataset_from_directory(
            str(data_dir / 'train'),
            color_mode='rgb',  
            seed=123,
            image_size=(224, 224),  
            batch_size=32
        )

        test_x = tf.keras.utils.image_dataset_from_directory(
            str(data_dir / 'test'),
            color_mode='rgb',  
            seed=123,
            image_size=(224, 224),  
            batch_size=32
        )
        
        val_x = tf.keras.utils.image_dataset_from_directory(
            str(data_dir / 'val'),
            color_mode='rgb',  
            seed=123,
            image_size=(224, 224),  
            batch_size=32
        )
        return (train_x, test_x, val_x)
    ```
    """)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### 2. Preprocess ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Augmentation Filtering, Normalization
                
    ‡∏ó‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ó‡∏£‡∏ô
    - Augment : ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (‡∏ö‡∏¥‡∏î‡∏†‡∏≤‡∏û, ‡∏Ç‡∏¢‡∏±‡∏ö, ‡∏´‡∏°‡∏∏‡∏ô, ‡∏ã‡∏π‡∏°) ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°
    - Normalization : ‡πÉ‡∏´‡πâ‡∏†‡∏≤‡∏û RGB Code ‡πÉ‡∏ô scale [0, 1]
                
    ```python
    # __builder_model.py

    def preprocess_image(train_x, test_x, val_x) -> tuple:
       
        # Preprocess rescaling an image bit in range [0, 1] 
        #
        # Args:
        #     train_x (Array)
        #     test_x (Array)
        #     val_x (Array)
        #
        # Returns:
        #     Tuple of (train_dataset, validation_dataset)

        # Augment Filtering
        datagen = ImageDataGenerator(
            rescale=1. / 255,
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            fill_mode='nearest'
        )

        def normalize(image, label):
            image = tf.cast(image, tf.float32) / 255.0
            return image, label

        # Normalize datasets
        train_x_norm = train_x.map(normalize)
        test_x_norm = test_x.map(normalize)
        val_x_norm = val_x.map(normalize)

        return (train_x_norm, test_x_norm, val_x_norm)
    ```
    """)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### 3. Building Model & Training
                
    - ‡∏ó‡∏≥‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏´‡∏£‡∏∑‡∏≠ Layers ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß 
    VGG16 model ‡∏à‡∏∂‡∏á‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Flatten ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡πÅ‡∏£‡∏Å‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ú‡πà‡∏≤‡∏ô VGG16 
    ‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡∏°‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤ Activation function ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö ‡πÇ‡∏î‡∏¢ FREEZING VGG16 ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏ß‡∏¢
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß base ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏ï‡∏±‡∏ß‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á) ‡πÑ‡∏°‡πà‡∏Ç‡∏¢‡∏±‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ó‡∏£‡∏ô    
    - ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å Building ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß Complie ‡πÄ‡∏õ‡πá‡∏ô Adam ‡∏ó‡∏µ‡πà init learning rate = 1e-3 ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô binary 
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÅ‡∏Ñ‡πà ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö
    - ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡∏à‡∏∞‡πÉ‡∏ä‡πâ early_stopping + checkpoint ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î learning rate ‡πÉ‡∏´‡πâ‡∏•‡∏î‡∏•‡∏á
    ‡πÅ‡∏•‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ‡∏´‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß overfit ‡∏à‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                
    ```python
    # __builder_model.py

    def modelsConstruct() -> tf.keras.models.Sequential:
                
        # Model builder using VGG16 as base model

        base_model = VGG16(
            include_top=False,
            weights="imagenet",
            input_shape=(224, 224, 3)  # Match image size and RGB channels
        )

        model = Sequential([
            base_model,
            Flatten(),
            BatchNormalization(),
            Dropout(0.5),
            Dense(1024, activation='relu'),
            Dropout(0.5),
            Dense(512, activation='relu'),
            Dropout(0.5),
            Dense(256, activation='relu'),
            Dropout(0.5),
            Dense(128, activation='relu'),
            Dropout(0.5),
            Dense(64, activation='relu'),
            Dropout(0.5),
            Dense(32, activation='relu'),
            Dropout(0.5),
            Dense(1, activation='sigmoid')
        ])

        base_model.trainable = False

        return model

    def modelsBuilt(model):
        model.compile(
            optimizer=Adam(learning_rate=0.0001),
            loss='binary_crossentropy',
            metrics=['accuracy', Recall(), Precision()]
        )

        model.summary()
        return model

    def training(train_data, val_data, model):
        # Add early stopping and model checkpoint
        early_stopping = EarlyStopping(
            monitor='val_loss', 
            patience=3, 
            restore_best_weights=True
        )
        
        model_checkpoint = ModelCheckpoint(
            'pneumonia_model.h5', 
            monitor='val_accuracy', 
            save_best_only=True
        )

        model.fit(
            train_data,
            epochs=10,
            validation_data=val_data,
            callbacks=[early_stopping, model_checkpoint]
        )
    ```
    """)
    st.markdown("""
        ##### Layer ‡∏ï‡πà‡∏≤‡∏á‡πÜ‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
    """)

    col1, col2 = st.columns([1, 2])
    with col1: 
        st.image("public/neural_network/workflow_model.png", use_container_width=1)
    with col2: 
        st.image("public/neural_network/workflow_model2.jpg", use_container_width=1)


    st.markdown("""
    ###### ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏î‡πâ [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://github.com/Chitchai-Jantanarak/IS-Streamlit/blob/main/train/neural_network/__builder_model.py)
    ---
    """)

def conclusion() -> None :
    st.markdown("<a id='conclusion'></a>", unsafe_allow_html=True)
    st.markdown("""
    ## Conclusion
                
    ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏°‡∏µ‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î **5 hr 48 mins** ‡∏°‡∏µ‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô
    - training flow
    - sample prediction images
    - confusion matrix
    - ROC curve
                
    ##### ‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
    ‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô Pneumonia ‡∏°‡∏≤‡∏Å‡∏à‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£ test ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà
    ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡∏à‡∏∂‡∏á‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏≠‡∏î‡∏≠‡∏±‡∏Å‡πÄ‡∏™‡∏ö‡∏°‡∏≤‡∏Å **TYPE I ERROR**
                
    ###### ‡∏™‡πà‡∏ß‡∏ô‡∏ú‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ô‡∏µ‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡πÑ‡∏î‡πâ [‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà](https://github.com/Chitchai-Jantanarak/IS-Streamlit/tree/main/train/neural_network)
                
    ‡∏õ‡∏•. ‡∏ó‡∏≥‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏≤‡∏¢‡∏ö‡πà‡∏≠‡∏¢ + ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏•‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö ;-;
    """,)

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### training flow
    """)
    st.image("public/neural_network/conclusion_training_flows.png")

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### sample prediction images (‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å Test file)
    """)
    st.image("public/neural_network/conclusion_sample_predictions.png")

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### confusion matrix
    """)
    st.image("public/neural_network/conclusion_confusion_matrix.png")

    st.markdown(""" <br /> """, unsafe_allow_html=1)
    st.markdown("""
    ##### ROC
    """)
    st.image("public/neural_network/conclusion_roc_curve.png")

def main():
    st.set_page_config(page_title="Neural Networks Explanation", page_icon="ü´Å")

    st.title(":red[Neural Networks]")
    st.markdown("---")

    preparation()
    workflow()
    conclusion()

    # Footer or additional content
    col1, col2, col3 = st.columns(3)
    if col3.button('Go to Model Page', use_container_width=1, type='primary'):
        st.switch_page("pages/4_NeuralNetwork-Model.py")

if __name__ == "__main__" :
    main()